---
title: 'Monarch: Expressive Structured Matrices for Efficient and Accurate Training'
date: 2025-05-31
permalink: /posts/2025/05/blog-post-3/
tags:
    - Pre-training
    - Fine-tuning
    - Matrix Decomposition
---

Monarch: Expressive Strucutred Matrices for Efficient and Accurate Training
======

# Abstract


limitations of replacing dense weight matrices with structured ones:

* end-to-end training: **unfavorable efficiency-quality tradeoffs**

* dense-to-sparse fine-tuning: **lack of tractable algorithms to approximate a given dense weight matrix**

Monarch matrix: 

* **hardware efficient**: parameterized as products of two block-diagonal matrics

* **expressive**: can represent many commonly used transforms

* **end-to-end sparse training applications**: speed up ViT and GPT-2 training by x2 

* **sparse-to-dense training**: speed up GPT-2 pretraining by x2

# Introduction

```python
def monarch_factorize(A):
    M = A.reshape(m, m, m, m)
    M = M.transpose(1, 2, 0, 3)
    U, S, V = np.linalg.svd(M)
    L = (U[:, :, :, 0] * S[:, :, :1] ** 0.5).transpose(0, 2, 1)
    R = (V[:, :, 0] * S[..., :1] ** 0.5).transpose(1, 0, 2)
    return L, R
    
```